{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://learn.deeplearning.ai/langchain-chat-with-your-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chatbot.properties as properties\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "embedding = OpenAIEmbeddings(openai_api_key=properties.OPENAI_KEY)\n",
    "persist_directory = \"chroma/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading, Chunking Input Documents, New DB and Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "\n",
    "directory = DirectoryLoader(\n",
    "    \"docs/\", glob=\"**/*.pdf\", show_progress=True, loader_cls=PyPDFLoader\n",
    ")\n",
    "pages = directory.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "chunk_size = 400\n",
    "chunk_overlap = 200\n",
    "\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \"(?<=\\. )\",\n",
    "        \" \",\n",
    "    ],\n",
    ")\n",
    "\n",
    "docs = r_splitter.split_documents(pages)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new db from documents\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs, embedding=embedding, persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving relevant chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reopen existing db\n",
    "\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Was macht Alexandre?\"\n",
    "# \"Was ist die Haltung der Autorin gegenüber Menschen in Indien, Nepal,  Rwanda, Tschad, Persien oder USA?\"\n",
    "# \"Sind Alf und Margrit rassistisch?\"\n",
    "# \"Was ist die Haltung der Autorin zu Religion?\"\n",
    "# \"Wo auf der Welt haben Margrit und Alf de Spindler Freunde oder Verwandte?\"\n",
    "# \"Welche Orte auf diese Welt haben die Autorin und ihr Ehemann Alf besucht?\"\n",
    "# \"Was sind die Stärken von Olaf, Irène, Christine, Thérèse?\"\n",
    "# \"Was sind die Stärken von Olaf, Irène, Christine, Thérèse?\"\n",
    "# \"Welche Konflikte gibt es in der Familie?\"\n",
    "# \"Gibt es Anzeichen von Demenz in der Familie?\"\n",
    "# \"Was wurde in Nepal erlebt?\"\n",
    "# \"Was macht Alexandre?\"\n",
    "# \"Was würde Alf auf die Frage 'wie geht es dir?' antworten?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(question, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.max_marginal_relevance_search(question, fetch_k=20, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GPT for question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=properties.OPENAI_KEY, model_name=\"gpt-4\", temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm, retriever=vectordb.as_retriever())\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "    Beantworte die Frage vom Benutzer mithilfe der Informationen, die du in den <texte>Texten</texte> aus den Weihnachtsbriefen findest.\n",
    "       \n",
    "    Wenn angebracht, verwende folgende zusätzliche Information über die Autorin:\n",
    "    <autorin>\n",
    "    Die Autorin nennt sich in den Briefen 'Mami'. Sie ist mit Alf de Spindler verheiratet. Die beiden haben vier Kinder: Olaf, Irene, Christine und Therese.\n",
    "    Olaf ist mit Jacqueline verheiratet und diese beiden haben zwei Kinder Jürg und Alexander. \n",
    "    Irene ist mit Martin verheiratet und diese beiden haben zwei Kinder Thomas und Stephan.\n",
    "    Christine hat die Töchter Sarah, Anne-Fränzi und Petrea.\n",
    "    Therese hat mit Roger zusammen die Tochter Vera.\n",
    "    </autorin>\n",
    "\n",
    "    Wenn du keine Antwort findest, sage dass du das nicht beantworten kannst. Vermeide es, eine Antwort zu erfinden.\n",
    "    Vermeide es, ungefragte Informationen zu erwähnen. Vermeide es, die Frage des Benutzers in deiner Antwort zu erwähnen.\n",
    "    Formuliere die Antwort so, wie sie die Autorin dieser Briefe selbst in einem Brief schreiben würde, jedoch ohne Begrüssung, Verabschiedung.\n",
    "\n",
    "    <texte>\n",
    "    {context}\n",
    "    </texte>\n",
    "\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Alexander, sein jUngerer Bruder, hat sich ordentlich eingefUgt in der Sekundarschule, \\nspielt auch weiter Querflote (ich finde, dass er Talent hat). Im Moment ist er ein \\nausgesprochener Militarfan. Mit Leidenschaft sammelt und kauft er sich Ausrüstungsge\\xad\\ngenstande aus Militarbestanden und stapelt sie in seinem Zimmer. Er traumt davon,', metadata={'page': 2, 'source': 'docs\\\\881200-Weihnachtsbrief.pdf'}),\n",
       " Document(page_content='Jürg, der ãltere Sohn von Jaqueline und Olav, bereitet sich zur \\nZeit auf sein Schlussexamen in Volkswirtschaft an der Uni Zürich \\nvor. Mit einem offentlichen, erfolgreichen Vortrag in Greifensee, \\nhat er gezeigt, dass er bestimmte politische Ansichten vertritt. \\nAlexander, 17 jahrig, fühlt sich im Gymnasium viel glücklicher als \\nin der Sekundarschule. In der Freizeit ist er am Rolibrett,', metadata={'page': 1, 'source': 'docs\\\\921200-Weihnachtsbrief.pdf'}),\n",
       " Document(page_content=\"hat er gezeigt, dass er bestimmte politische Ansichten vertritt. \\nAlexander, 17 jahrig, fühlt sich im Gymnasium viel glücklicher als \\nin der Sekundarschule. In der Freizeit ist er am Rolibrett, \\nSnowboard und am Felsklettern interessiert. \\nChristine's und Heinz's Tochter Sarah, Anne-Franz und Petrea \\nschwarmen vorlaufig noch für das Theater und Literatur. Alle drei\", metadata={'page': 1, 'source': 'docs\\\\921200-Weihnachtsbrief.pdf'}),\n",
       " Document(page_content='zu tun ist, dass wir nicht eines Tages in unserem Abfall ersticken. \\nAlexander wird wohl auch bald fragen, ob es bei mir unten regne, denn seine Beine \\nsind so lang geworden. Er sei auf dem Weg, ein Tennis-Champion zu werden, das sei \\nsein Lieblingssport. In diesem Winter hat er vor, sich im Snowboard-Sport auszu\\xad\\nbilden und darum will er seine Weihnachtsferien mit uns auf dem Hasliberg verbrin\\xad', metadata={'page': 2, 'source': 'docs\\\\891100-Weihnachtsbrief.pdf'})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question})\n",
    "result[\"source_documents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Benutzer: Was macht Alexander in seiner Freizeit?\\n\\nAssistent: Alexander hat eine Vielzahl von Interessen. Er spielt Querflöte und ich finde, dass er Talent hat. Er ist auch ein ausgesprochener Militärfan und sammelt mit Leidenschaft Ausrüstungsgegenstände aus Militärbeständen. In seiner Freizeit ist er auch am Rolibrett, Snowboard und am Felsklettern interessiert. Er träumt davon, ein Tennis-Champion zu werden und plant, sich diesen Winter im Snowboard-Sport auszubilden. Er wird seine Weihnachtsferien mit uns auf dem Hasliberg verbringen, um dies zu tun.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
